# üß† RAG con Flask ‚Äì Buscador y Resumen Inteligente

Este proyecto implementa un sistema de **RAG (Retrieval-Augmented Generation)** desarrollado con **Flask** como interfaz web.  
El objetivo es permitir al usuario **cargar un documento y realizar preguntas sobre su contenido** o **generar un resumen autom√°tico**, aprovechando la combinaci√≥n de **b√∫squeda sem√°ntica**, **procesamiento de lenguaje natural** y **modelos de lenguaje (LLM)**.

---

## üìå ¬øQu√© es un RAG?

Un **RAG (Retrieval-Augmented Generation)** es una arquitectura que combina:

1. **Recuperaci√≥n de informaci√≥n (Retrieval)** ‚Üí Se buscan fragmentos relevantes en un conjunto de documentos (chunks) mediante embeddings y m√©tricas de similitud.  
2. **Generaci√≥n de texto (Generation)** ‚Üí Los fragmentos recuperados se utilizan como **contexto adicional** para un modelo de lenguaje (LLM), que produce una respuesta fundamentada en la informaci√≥n del documento.

En pocas palabras: el RAG **permite que un modelo de lenguaje responda bas√°ndose en tus documentos**, no solo en su conocimiento interno.

---

## ‚öôÔ∏è Funcionalidades del proyecto

La aplicaci√≥n cuenta con **dos funcionalidades principales** accesibles desde la interfaz web:

### üß© 1. Buscador inteligente

El usuario puede:

1. Escribir una **pregunta o consulta (prompt)**.  
2. Cargar un **documento en formato `.txt` o `.pdf`**.

El sistema realiza los siguientes pasos:

- **Divisi√≥n en chunks (fragmentos) con solapamiento (overlap):**  
  El texto se divide para facilitar la b√∫squeda de informaci√≥n relevante sin perder contexto.
- **Generaci√≥n de embeddings:**  
  Se crean representaciones vectoriales tanto de los chunks como de la pregunta del usuario.
- **B√∫squeda sem√°ntica (similaridad coseno):**  
  Se identifican los fragmentos m√°s similares al prompt.
- **Selecci√≥n de contexto (Top-k):**  
  Se concatenan los fragmentos m√°s relevantes.
- **Consulta al LLM v√≠a API:**  
  El modelo recibe el contexto + el prompt, y genera una respuesta fundamentada.  
  Si la respuesta no est√° en el documento, el modelo debe informar de ello.

---

### üìù 2. Resumen autom√°tico de documentos

La nueva funcionalidad permite **resumir textos extensos** (en `.txt` o `.pdf`), incluso aquellos con m√°s de **80 000 palabras**.

El proceso es el siguiente:

1. Se divide el documento en **chunks grandes** (p. ej., 10 000 palabras con solapamiento).  
2. Cada chunk se resume individualmente mediante el modelo de lenguaje.  
3. Los res√∫menes parciales se combinan y se realiza un **meta-resumen global** que sintetiza toda la informaci√≥n manteniendo coherencia y eliminando redundancias.

De esta forma, el usuario obtiene un **resumen completo, coherente y compacto** incluso para documentos extensos.

---

## üñ•Ô∏è Interfaz

- La aplicaci√≥n cuenta con un **frontend simple y limpio en Flask**, con dos formularios:
  - üß† Uno para **consultas y preguntas** sobre el contenido.
  - üìù Otro para **resumir el documento completo**.
- Las respuestas y res√∫menes se muestran en formato **Markdown renderizado**, permitiendo listas, tablas o fragmentos de c√≥digo.
- Se gestionan los errores de forma clara (archivos no v√°lidos, formato incorrecto, etc.).

---

## üõ†Ô∏è Tecnolog√≠as utilizadas

- **Backend:** Flask (Python)  
- **Procesamiento de texto:** Chunking con overlap, embeddings sem√°nticos  
- **Similitud:** Distancia coseno  
- **Modelos de lenguaje:** LLMs accesibles mediante API (por ejemplo, `openai/gpt-oss-20b:free`)  
- **Frontend:** Formularios HTML con plantillas Jinja2  
- **Lectura de documentos:** PyPDF2 para PDFs, lectura directa para TXT  
- **Markdown rendering:** Librer√≠a `markdown` de Python  
- **Formatos soportados:** `.txt` y `.pdf`

